{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import os\n",
    "\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "\n",
    "# BERT from Huggingface\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "# Extra additional packages/functions\n",
    "from balancers import BinaryBalancer\n",
    "from utils import calculate_bias_metrics, eo_postprocess, calc_gen_bounds, BertClassifier, train, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fifa 20 dataset\n",
    "all_data = pd.read_csv('players_20.csv')\n",
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of players: 2883\n"
     ]
    }
   ],
   "source": [
    "# Set the nationalities you want to use\n",
    "nationalities = ['England','Germany']\n",
    "\n",
    "# Keep relevant columns\n",
    "o_data = all_data[['long_name','age','nationality','overall','wage_eur']].copy(deep = True)\n",
    "\n",
    "# Change column names of nationality and wage_eur to a and y \n",
    "o_data.rename(columns = {'nationality':'a', 'wage_eur':'y'}, inplace = True)\n",
    "\n",
    "# Restrict to specified nationalities\n",
    "o_data = o_data.loc[(o_data['a'].isin([nationalities[0], nationalities[1]]))]\n",
    "print('Number of players:', o_data.shape[0])\n",
    "\n",
    "# Only keep relevant feagires and outcomes\n",
    "data = o_data[['long_name','age','a','overall','y']].copy(deep = True)\n",
    "\n",
    "# Binarize nationality\n",
    "data = data.replace(nationalities[0],0)\n",
    "data = data.replace(nationalities[1],1)\n",
    "\n",
    "# Reset the index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Binarize outcome using median outcome\n",
    "data.loc[data['y'] < np.median(data['y']), 'y'] = 0\n",
    "data.loc[data['y'] >= np.median(data['y']), 'y'] = 1\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min rate =  0.19944502254595908\n"
     ]
    }
   ],
   "source": [
    "# Create new column to stratify data and calculate base rates\n",
    "group = []\n",
    "for i in range(data.shape[0]):\n",
    "    # w\n",
    "    if np.sum(data[['a','y']].iloc[i] == [0,0]) == 2:\n",
    "        group.append(1)\n",
    "    # v\n",
    "    if np.sum(data[['a','y']].iloc[i] == [1,0]) == 2:\n",
    "        group.append(2)\n",
    "    # s\n",
    "    if np.sum(data[['a','y']].iloc[i] == [0,1]) == 2:\n",
    "        group.append(3)\n",
    "    # r\n",
    "    if np.sum(data[['a','y']].iloc[i] == [1,1]) == 2:\n",
    "        group.append(4)\n",
    "\n",
    "# Add column to the data\n",
    "data['group'] = group\n",
    "\n",
    "# Calculate base rates\n",
    "total = data.shape[0]\n",
    "r = np.sum(data['group'] == 4)/total\n",
    "s = np.sum(data['group'] == 3)/total\n",
    "v = np.sum(data['group'] == 2)/total\n",
    "w= np.sum(data['group'] == 1)/total\n",
    "print('min rate = ', min(r,s,w,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Experiment Parameters\n",
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "LR = 1e-6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into necessary datasets\n",
    "d_xa, d_remain = train_test_split(data, train_size = 0.7, stratify=data['group'],random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:37<00:00, 20.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.657             | Train Accuracy:  0.612             | Val Loss:  0.507             | Val Accuracy:  0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:38<00:00, 19.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.446             | Train Accuracy:  0.858             | Val Loss:  0.359             | Val Accuracy:  0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:38<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.338             | Train Accuracy:  0.892             | Val Loss:  0.294             | Val Accuracy:  0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:33<00:00, 22.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.261             | Train Accuracy:  0.919             | Val Loss:  0.284             | Val Accuracy:  0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:36<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.200             | Train Accuracy:  0.939             | Val Loss:  0.268             | Val Accuracy:  0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:38<00:00, 19.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.155             | Train Accuracy:  0.955             | Val Loss:  0.273             | Val Accuracy:  0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:37<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.136             | Train Accuracy:  0.963             | Val Loss:  0.267             | Val Accuracy:  0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:37<00:00, 20.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.110             | Train Accuracy:  0.971             | Val Loss:  0.287             | Val Accuracy:  0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:38<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.091             | Train Accuracy:  0.972             | Val Loss:  0.305             | Val Accuracy:  0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:38<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.079             | Train Accuracy:  0.980             | Val Loss:  0.316             | Val Accuracy:  0.899\n"
     ]
    }
   ],
   "source": [
    "# Split d_xa into d_xa_train and d_xa_val\n",
    "d_xa_train, d_xa_val = train_test_split(d_xa, train_size = 0.75, stratify=d_xa['group'],random_state=10)\n",
    "\n",
    "# Train model\n",
    "train(model, d_xa_train, d_xa_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cuda\n",
    "os.environ['CUDE_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating final validation accuracy and ROC curve\n",
    "val = Dataset(d_xa_val)\n",
    "val_dataloader = torch.utils.data.DataLoader(val, batch_size=len(d_xa_val))\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    for val_input, val_label, val_remain in val_dataloader:\n",
    "        val_label = val_label.to(device).float()\n",
    "        mask = val_input['attention_mask'].to(device)\n",
    "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "        output = model(input_id, mask).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold =  0.03406813627254509\n",
      "Lowest error =  0.0891089108910891\n"
     ]
    }
   ],
   "source": [
    "# Optimal Threshold for accuracy of a_hat\n",
    "total_error = []\n",
    "thresholds = np.linspace(0,1,500)\n",
    "for t in thresholds:\n",
    "    a_hat = (output.cpu() >= t)\n",
    "    a_hat = a_hat.numpy().astype('int')\n",
    "\n",
    "    # Error of h(x) on this data\n",
    "    incorrect = np.sum((d_xa_val['a'] != a_hat))\n",
    "    error = (incorrect)/(d_xa_val.shape[0])\n",
    "    total_error.append(error)\n",
    "\n",
    "total_error = np.array(total_error)\n",
    "opt_t = thresholds[np.argmin(total_error)]\n",
    "print('Optimal threshold = ', opt_t)\n",
    "# plt.plot(thresholds,total_error)\n",
    "# plt.xlabel('Thresholds')\n",
    "# plt.ylabel('Error')\n",
    "# plt.plot(thresholds,total_error)\n",
    "print('Lowest error = ', np.min(total_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary function\n",
    "def generate_estimates(t,output,d_xy_test):\n",
    "    # Add a_hat column to data using opt_t\n",
    "    a_hat = (output.cpu()) >= t\n",
    "    d_xy_test['a_hat'] = a_hat.numpy().astype('int')\n",
    "\n",
    "    # Error of h(x) on this data\n",
    "    incorrect = np.sum((d_xy_test['a'] != d_xy_test['a_hat']))\n",
    "    error = (incorrect)/(d_xy_test.shape[0])\n",
    "    #print('a_error = ', error)\n",
    "\n",
    "    y1 = d_xy_test[d_xy_test['y'] == 1]\n",
    "    incorrect = np.sum(y1['a_hat'] != y1['a'])/y1.shape[0]\n",
    "    U1 = incorrect*(y1.shape[0]/d_xy_test.shape[0])\n",
    "    y0 = d_xy_test[d_xy_test['y'] == 0]\n",
    "    incorrect = np.sum(y0['a_hat'] != y0['a'])/y0.shape[0]\n",
    "    U2 = incorrect*(y0.shape[0]/d_xy_test.shape[0])\n",
    "\n",
    "    # Evaluate the equal oppurtunity violation using a_hat using threshold of 0.5 for f\n",
    "    a1_y1 = d_xy_test[(d_xy_test['a_hat'] == 1) & (d_xy_test['y'] == 1)]\n",
    "    a0_y1 = d_xy_test[(d_xy_test['a_hat'] == 0) & (d_xy_test['y'] == 1)]\n",
    "    a1_y0 = d_xy_test[(d_xy_test['a_hat'] == 1) & (d_xy_test['y'] == 0)]\n",
    "    a0_y0 = d_xy_test[(d_xy_test['a_hat'] == 0) & (d_xy_test['y'] == 0)]\n",
    "    alpha_hat = np.sum((a1_y1['y_prob'] >= 0.5) == 1)/a1_y1.shape[0]\n",
    "    beta_hat = np.sum((a0_y1['y_prob'] >= 0.5) == 1)/a0_y1.shape[0]\n",
    "    tau_hat = np.sum((a1_y0['y_prob'] >= 0.5) == 1)/a1_y0.shape[0]\n",
    "    phi_hat = np.sum((a0_y0['y_prob'] >= 0.5) == 1)/a0_y0.shape[0]\n",
    "    bias_tpr_hat = np.abs(alpha_hat - beta_hat)\n",
    "    bias_fpr_hat = np.abs(tau_hat - phi_hat)\n",
    "    # k1 = 1 + (error/(2*s**2*r**2))*((2*r**4*s + 2*s**4*r - error*r**4 - error*s**4 + error*r**2*s**2)/(2*r*s - error*s - error*r))\n",
    "    # print('Lower bound =', bias_tpr_hat)\n",
    "    # print('Upper bound = ', bias_tpr_hat*k1)\n",
    "    # print('bias_tpr_hat =', bias_tpr_hat)\n",
    "\n",
    "    return bias_tpr_hat, bias_fpr_hat, error, U1, U2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82994/2146228505.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gamma_1 = np.abs(1-g1-g2)/(((s/r)*(1-g1)+g2)*((r/s)*(1-g2)+g1))\n",
      "/tmp/ipykernel_82994/2146228505.py:140: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gamma_2 = np.abs(1-d1-d2)/(((v/w)*(1-d1)+d2)*((w/v)*(1-d2)+d1))\n",
      "/tmp/ipykernel_82994/2146228505.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  gamma_1 = np.abs(1-g1-g2)/(((s/r)*(1-g1)+g2)*((r/s)*(1-g2)+g1))\n"
     ]
    }
   ],
   "source": [
    "# Will repeatedly split data into\n",
    "# d_xy_train\n",
    "# d_xy_test\n",
    "# d_xy_tune\n",
    "# Split data \n",
    "true_bias_tpr = []\n",
    "true_bias_fpr = []\n",
    "old_bias_tpr = []\n",
    "old_bias_fpr = []\n",
    "new_bias_tpr = []\n",
    "new_bias_fpr = []\n",
    "old_error = []\n",
    "U1_old = []\n",
    "U2_old = []\n",
    "new_error_tpr = []\n",
    "new_error_fpr = []\n",
    "new_bias_tpr = []\n",
    "new_bias_fpr = []\n",
    "U1_new_tpr = []\n",
    "U2_new_tpr = []\n",
    "U1_new_fpr = []\n",
    "U2_new_fpr = []\n",
    "thresholds = np.linspace(0,1,101)\n",
    "\n",
    "for i in range(50):\n",
    "    d_xy_train, d_xy_remain = train_test_split(d_remain, train_size = 0.8, stratify=d_remain['group'])\n",
    "    d_xy_test, d_xay = train_test_split(d_xy_remain, train_size = 0.5, stratify=d_xy_remain['group'])\n",
    "\n",
    "    # Create Classifier\n",
    "    clf = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "    # Split data into features and labels\n",
    "    x_train = d_xy_train[['age','overall']]\n",
    "    y_train = d_xy_train['y']\n",
    "    x_test = d_xy_test[['age','overall']]\n",
    "    y_test = d_xy_test['y']\n",
    "\n",
    "    # Fit classifier\n",
    "    clf.fit(x_train.to_numpy(),y_train)\n",
    "\n",
    "    # Model Accuracy:\n",
    "    # print(\"Accuracy:\",metrics.accuracy_score(y_test, clf.predict(x_test.to_numpy())))\n",
    "\n",
    "    # Evaluate probabilities on test set\n",
    "    y_prob = clf.predict_proba(x_test.to_numpy())\n",
    "    \n",
    "    # Add y_prob to data\n",
    "    d_xy_test['y_prob'] = y_prob[:,1]\n",
    "\n",
    "    # Calculating hat_a\n",
    "    xy_test = Dataset(d_xy_test)\n",
    "    xy_test_dataloader = torch.utils.data.DataLoader(xy_test, batch_size=len(xy_test))\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xy_test_input, xy_test_label, xy_test_remain in xy_test_dataloader:\n",
    "            xy_test_label = xy_test_label.to(device).float()\n",
    "            mask = xy_test_input['attention_mask'].to(device)\n",
    "            input_id = xy_test_input['input_ids'].squeeze(1).to(device)\n",
    "            output = model(input_id, mask).reshape(1,-1)[0]\n",
    "    \n",
    "    # Evaluate true bias\n",
    "    a1_y1 = d_xy_test[(d_xy_test['a'] == 1) & (d_xy_test['y'] == 1)]\n",
    "    a0_y1 = d_xy_test[(d_xy_test['a'] == 0) & (d_xy_test['y'] == 1)]\n",
    "    a1_y0 = d_xy_test[(d_xy_test['a'] == 1) & (d_xy_test['y'] == 0)]\n",
    "    a0_y0 = d_xy_test[(d_xy_test['a'] == 0) & (d_xy_test['y'] == 0)]\n",
    "    alpha = np.sum((a1_y1['y_prob'] >= 0.5) == 1)/a1_y1.shape[0]\n",
    "    beta = np.sum((a0_y1['y_prob'] >= 0.5) == 1)/a0_y1.shape[0]\n",
    "    tau = np.sum((a1_y0['y_prob'] >= 0.5) == 1)/a1_y0.shape[0]\n",
    "    phi = np.sum((a0_y0['y_prob'] >= 0.5) == 1)/a0_y0.shape[0]\n",
    "    true_bias_tpr.append(np.abs(alpha - beta))\n",
    "    true_bias_fpr.append(np.abs(tau - phi))\n",
    "    # print('bias_tpr =', bias_tpr)\n",
    "\n",
    "    # Use generate estimates function\n",
    "    bias_tpr_hat_o, bias_fpr_hat_o, a_error, error_1, error_2 = generate_estimates(opt_t,output,d_xy_test)\n",
    "    old_bias_tpr.append(bias_tpr_hat_o)\n",
    "    old_bias_fpr.append(bias_fpr_hat_o)\n",
    "    old_error.append(a_error)\n",
    "    U1_old.append(error_1)\n",
    "    U2_old.append(error_2)\n",
    "\n",
    "    #### Tuning\n",
    "    # Tune h(x) on common data \n",
    "    d_tune = Dataset(d_xay)\n",
    "    d_tune_dataloader = torch.utils.data.DataLoader(d_tune, batch_size=len(d_xay))\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for tune_input, tune_label, tune_remain in d_tune_dataloader:\n",
    "            tune_label = tune_label.to(device).float()\n",
    "            mask = tune_input['attention_mask'].to(device)\n",
    "            input_id = tune_input['input_ids'].squeeze(1).to(device)\n",
    "            tune_output = model(input_id, mask).reshape(1,-1)[0]\n",
    "\n",
    "    # Processing data for later calculations\n",
    "    tune_label = np.array(tune_label.cpu())\n",
    "    tune_output = np.array(tune_output.cpu())\n",
    "    tune_remain = np.array(tune_remain.cpu())\n",
    "    tune_Y = []\n",
    "    for i in range(len(tune_remain)):\n",
    "        tune_Y.append(tune_remain[i][2])\n",
    "    tune_Y = np.array(tune_Y)\n",
    "    \n",
    "    # Concatenate y, a_label_test, outcomes_test to understand the error rates as function of threshold \n",
    "    Y_A_Ap = np.hstack((tune_Y.reshape(-1,1),tune_label.reshape(-1,1),tune_output.reshape(-1,1)))\n",
    "    Y_A = Y_A_Ap[:,:2]\n",
    "\n",
    "    # Look at error rates as a function of thresholds\n",
    "    g1 = []\n",
    "    g2 = []\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for thresh in thresholds:\n",
    "        A_pred = (Y_A_Ap[:,2] >= thresh)\n",
    "        # g1\n",
    "        indices = np.where(np.sum(Y_A == [1,0],axis = 1) == 2)\n",
    "        A_labels = A_pred[indices]\n",
    "        g1.append(np.sum(Y_A[:,1][indices] != A_labels)/(np.size(indices)))\n",
    "        # g2\n",
    "        indices = np.where(np.sum(Y_A == [1,1],axis = 1) == 2)\n",
    "        A_labels = A_pred[indices]\n",
    "        g2.append(np.sum(Y_A[:,1][indices] != A_labels)/(np.size(indices)))\n",
    "        # h1\n",
    "        indices = np.where(np.sum(Y_A == [0,0],axis = 1) == 2)\n",
    "        A_labels = A_pred[indices]\n",
    "        d1.append(np.sum(Y_A[:,1][indices] != A_labels)/(np.size(indices)))\n",
    "        # h2\n",
    "        indices = np.where(np.sum(Y_A == [0,1],axis = 1) == 2)\n",
    "        A_labels = A_pred[indices]\n",
    "        d2.append(np.sum(Y_A[:,1][indices] != A_labels)/(np.size(indices)))\n",
    "\n",
    "    g1 = np.array(g1)\n",
    "    g2 = np.array(g2)\n",
    "    d1 = np.array(d1)\n",
    "    d2 = np.array(d2)\n",
    "\n",
    "    # Calculating gamma_1 and gamma_2\n",
    "    gamma_1 = np.abs(1-g1-g2)/(((s/r)*(1-g1)+g2)*((r/s)*(1-g2)+g1))\n",
    "\n",
    "    # Calculating gamma_1 and gamma_2\n",
    "    gamma_2 = np.abs(1-d1-d2)/(((v/w)*(1-d1)+d2)*((w/v)*(1-d2)+d1))\n",
    "\n",
    "    # Optimal threshold for gamma_1 maximization or gamma_2 maximization\n",
    "    nan_ind1 = np.where(np.isnan(gamma_1) == True)[0]\n",
    "    nan_ind2 = np.where(np.isnan(gamma_2) == True)[0]\n",
    "    nan_ind = np.concatenate([nan_ind1, nan_ind2[~np.isin(nan_ind2,nan_ind1)]])\n",
    "\n",
    "    # Remove nan\n",
    "    gamma_1 = np.delete(gamma_1, nan_ind)\n",
    "    gamma_2 = np.delete(gamma_2, nan_ind)\n",
    "    g1 = np.delete(g1,nan_ind)\n",
    "    g2 = np.delete(g2,nan_ind)\n",
    "    h1 = np.delete(d1,nan_ind)\n",
    "    h2 = np.delete(d2,nan_ind)\n",
    "    thresholds = np.delete(thresholds,nan_ind)\n",
    "\n",
    "    # Optimal Thresholds for various tasks\n",
    "    opt_t_gamma_1 = thresholds[np.argmax(gamma_1)]\n",
    "    opt_t_gamma_2 = thresholds[np.argmax(gamma_2)]\n",
    "    # print(opt_t_gamma_1)\n",
    "    # print(\"Optimal Threshold for max gamma_1\",opt_t_gamma_1)\n",
    "    # print(\"Optimal Threshold for max gamma_2\",opt_t_gamma_2)\n",
    "\n",
    "    # Add a_hat column to data using opt_t_gamma_1\n",
    "    bias_tpr_hat_n, bias_fpr_hat_n, a_error, error_1, error_2 = generate_estimates(opt_t_gamma_1,output,d_xy_test)\n",
    "    new_bias_tpr.append(bias_tpr_hat_n)\n",
    "    new_error_tpr.append(a_error)\n",
    "    U1_new_tpr.append(error_1)\n",
    "    U2_new_tpr.append(error_2)\n",
    "\n",
    "    # Add a_hat column to data using opt_t_gamma_1\n",
    "    bias_tpr_hat_n, bias_fpr_hat_n, a_error, error_1, error_2 = generate_estimates(opt_t_gamma_2,output,d_xy_test)\n",
    "    new_bias_fpr.append(bias_fpr_hat_n)\n",
    "    new_error_fpr.append(a_error)\n",
    "    U1_new_fpr.append(error_1)\n",
    "    U2_new_fpr.append(error_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating differences\n",
    "old_diff_tpr = np.abs(np.array(old_bias_tpr) - np.array(true_bias_tpr)).reshape(-1,1)\n",
    "new_diff_tpr = np.abs(np.array(new_bias_tpr) - np.array(true_bias_tpr)).reshape(-1,1)\n",
    "diffs_tpr = np.concatenate((old_diff_tpr,new_diff_tpr),axis = 1)\n",
    "\n",
    "old_diff_fpr = np.abs(np.array(old_bias_fpr) - np.array(true_bias_fpr)).reshape(-1,1)\n",
    "new_diff_fpr = np.abs(np.array(new_bias_fpr) - np.array(true_bias_fpr)).reshape(-1,1)\n",
    "diffs_fpr = np.concatenate((old_diff_fpr,new_diff_fpr),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Difference in TPR pre and post tuning gamma\n",
    "plt.boxplot(diffs_tpr,patch_artist=True)\n",
    "plt.xticks([1, 2], [r'$\\Delta_{TPR}$', r'$\\Delta^c_{TPR}$'])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.savefig('Figures/Exp3/better_estimation.png',bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Difference in U pre and post tuning gamma\n",
    "plt.boxplot(np.abs(np.array(U1_old) - np.array(U1_new_tpr)),patch_artist=True)\n",
    "plt.xticks([1], [r'$\\Delta_{U_1}$'])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.savefig('Figures/Exp3/deltaU.png',bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cuda102')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3480f17d4fb79fd692b6ed7a9ca0948306936357486d7718056d429d227b38c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
